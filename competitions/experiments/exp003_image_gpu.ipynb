{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "612d44d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:14.552623Z",
     "iopub.status.busy": "2025-12-14T14:59:14.552354Z",
     "iopub.status.idle": "2025-12-14T14:59:15.296072Z",
     "shell.execute_reply": "2025-12-14T14:59:15.295136Z"
    },
    "papermill": {
     "duration": 0.749762,
     "end_time": "2025-12-14T14:59:15.297495",
     "exception": false,
     "start_time": "2025-12-14T14:59:14.547733",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'kauto'...\r\n",
      "remote: Enumerating objects: 125, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (125/125), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (98/98), done.\u001b[K\r\n",
      "remote: Total 125 (delta 22), reused 119 (delta 16), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (125/125), 195.46 KiB | 7.82 MiB/s, done.\r\n",
      "Resolving deltas: 100% (22/22), done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tatsukisato/kauto.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "147c4f38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:15.305403Z",
     "iopub.status.busy": "2025-12-14T14:59:15.304664Z",
     "iopub.status.idle": "2025-12-14T14:59:15.308156Z",
     "shell.execute_reply": "2025-12-14T14:59:15.307582Z"
    },
    "papermill": {
     "duration": 0.008448,
     "end_time": "2025-12-14T14:59:15.309230",
     "exception": false,
     "start_time": "2025-12-14T14:59:15.300782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd /kaggle/working/kauto\n",
    "# !git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c251c676",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:15.315934Z",
     "iopub.status.busy": "2025-12-14T14:59:15.315760Z",
     "iopub.status.idle": "2025-12-14T14:59:15.318772Z",
     "shell.execute_reply": "2025-12-14T14:59:15.318257Z"
    },
    "papermill": {
     "duration": 0.007667,
     "end_time": "2025-12-14T14:59:15.319855",
     "exception": false,
     "start_time": "2025-12-14T14:59:15.312188",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2932e023",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:15.326689Z",
     "iopub.status.busy": "2025-12-14T14:59:15.326189Z",
     "iopub.status.idle": "2025-12-14T14:59:26.253506Z",
     "shell.execute_reply": "2025-12-14T14:59:26.252716Z"
    },
    "papermill": {
     "duration": 10.932275,
     "end_time": "2025-12-14T14:59:26.254951",
     "exception": false,
     "start_time": "2025-12-14T14:59:15.322676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0ce5d70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:26.262108Z",
     "iopub.status.busy": "2025-12-14T14:59:26.261752Z",
     "iopub.status.idle": "2025-12-14T14:59:26.265291Z",
     "shell.execute_reply": "2025-12-14T14:59:26.264733Z"
    },
    "papermill": {
     "duration": 0.008181,
     "end_time": "2025-12-14T14:59:26.266344",
     "exception": false,
     "start_time": "2025-12-14T14:59:26.258163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_kaggle() -> bool:\n",
    "    return \"KAGGLE_KERNEL_RUN_TYPE\" in os.environ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef1c5d00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:26.273115Z",
     "iopub.status.busy": "2025-12-14T14:59:26.272826Z",
     "iopub.status.idle": "2025-12-14T14:59:26.451187Z",
     "shell.execute_reply": "2025-12-14T14:59:26.450619Z"
    },
    "papermill": {
     "duration": 0.183068,
     "end_time": "2025-12-14T14:59:26.452360",
     "exception": false,
     "start_time": "2025-12-14T14:59:26.269292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add project root to path to import src\n",
    "if is_kaggle:\n",
    "    sys.path.append(str(Path.cwd() / \"kauto\" / \"competitions\"))\n",
    "else:\n",
    "    sys.path.append(str(Path(__file__).resolve().parents[1]))\n",
    "\n",
    "from src.utils import setup_directories, save_results, create_submission, print_experiment_info, crop_and_save_images\n",
    "from src.image_dataset import ImageDataset\n",
    "from src.cnn_model import SimpleCNN\n",
    "from src.dataset import AtmaCup22Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bbf0634",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:26.459098Z",
     "iopub.status.busy": "2025-12-14T14:59:26.458875Z",
     "iopub.status.idle": "2025-12-14T14:59:26.468926Z",
     "shell.execute_reply": "2025-12-14T14:59:26.468158Z"
    },
    "papermill": {
     "duration": 0.014773,
     "end_time": "2025-12-14T14:59:26.470136",
     "exception": false,
     "start_time": "2025-12-14T14:59:26.455363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"exp003_image_gpu\"\n",
    "description = \"Image-based baseline with ResNet18 (Frozen backbone). Train on Q1, Val on Q2.\"\n",
    "print_experiment_info(exp_name, description)\n",
    "\n",
    "dirs = setup_directories(base_dir=Path(\"/kaggle/working/kauto/competitions\"), data_dir=Path(\"/kaggle/input/atmacup22\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e75b8b91",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:26.477588Z",
     "iopub.status.busy": "2025-12-14T14:59:26.477135Z",
     "iopub.status.idle": "2025-12-14T14:59:26.549322Z",
     "shell.execute_reply": "2025-12-14T14:59:26.548633Z"
    },
    "papermill": {
     "duration": 0.077334,
     "end_time": "2025-12-14T14:59:26.550367",
     "exception": false,
     "start_time": "2025-12-14T14:59:26.473033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (24920, 9)\n",
      "Test data shape: (9223, 9)\n"
     ]
    }
   ],
   "source": [
    "# 1. Load Data\n",
    "dataset_handler = AtmaCup22Dataset(data_dir=str(dirs['raw']))\n",
    "train_meta, test_meta = dataset_handler.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2beffaba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:26.557509Z",
     "iopub.status.busy": "2025-12-14T14:59:26.557013Z",
     "iopub.status.idle": "2025-12-14T14:59:26.583440Z",
     "shell.execute_reply": "2025-12-14T14:59:26.582695Z"
    },
    "papermill": {
     "duration": 0.03106,
     "end_time": "2025-12-14T14:59:26.584518",
     "exception": false,
     "start_time": "2025-12-14T14:59:26.553458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (Q1): 6410\n",
      "Val set (Q2): 18510\n"
     ]
    }
   ],
   "source": [
    "# 2. Prepare Data Splitting\n",
    "# Train: Q1, Val: Q2\n",
    "# Filter by quarter string\n",
    "train_df = train_meta[train_meta['quarter'].str.contains('Q1')].copy()\n",
    "val_df = train_meta[train_meta['quarter'].str.contains('Q2')].copy()\n",
    "\n",
    "print(f\"Train set (Q1): {len(train_df)}\")\n",
    "print(f\"Val set (Q2): {len(val_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b236cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:26.591395Z",
     "iopub.status.busy": "2025-12-14T14:59:26.591200Z",
     "iopub.status.idle": "2025-12-14T14:59:27.003293Z",
     "shell.execute_reply": "2025-12-14T14:59:27.002507Z"
    },
    "papermill": {
     "duration": 0.417007,
     "end_time": "2025-12-14T14:59:27.004500",
     "exception": false,
     "start_time": "2025-12-14T14:59:26.587493",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing cropped images in /kaggle/input/atmacup22/data/processed/crops_train\n"
     ]
    }
   ],
   "source": [
    "# 3. Check/Generate Cropped Images\n",
    "# We store generated crops in data/processed/crops_train\n",
    "crops_dir = dirs['processed'] / 'crops_train'\n",
    "\n",
    "# Check if crops exist for all training data (Q1+Q2)\n",
    "# We use the length of original train_meta because indices are based on it\n",
    "# and we want to ensure all potential images are processed if we change split later\n",
    "if not crops_dir.exists() or len(list(crops_dir.glob(\"*.jpg\"))) < len(train_meta) * 0.9: \n",
    "    # *0.9 allows for some missing/failed crops, but ideally should be full.\n",
    "    # Let's just generate if dir doesn't exist or seems empty\n",
    "    print(f\"Generating cropped images to {crops_dir}...\")\n",
    "    crop_and_save_images(train_meta, dirs['raw'], crops_dir, mode='train')\n",
    "else:\n",
    "    print(f\"Using existing cropped images in {crops_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3e1e9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:27.013902Z",
     "iopub.status.busy": "2025-12-14T14:59:27.013380Z",
     "iopub.status.idle": "2025-12-14T14:59:27.018452Z",
     "shell.execute_reply": "2025-12-14T14:59:27.017759Z"
    },
    "papermill": {
     "duration": 0.009874,
     "end_time": "2025-12-14T14:59:27.019532",
     "exception": false,
     "start_time": "2025-12-14T14:59:27.009658",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4. Transforms\n",
    "# cv2 reads as numpy array (H, W, C). ToPILImage converts to PIL.\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), \n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21aaa25d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:27.026507Z",
     "iopub.status.busy": "2025-12-14T14:59:27.026172Z",
     "iopub.status.idle": "2025-12-14T14:59:27.030534Z",
     "shell.execute_reply": "2025-12-14T14:59:27.029824Z"
    },
    "papermill": {
     "duration": 0.009041,
     "end_time": "2025-12-14T14:59:27.031603",
     "exception": false,
     "start_time": "2025-12-14T14:59:27.022562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 5. Datasets & Loaders\n",
    "train_dataset = ImageDataset(train_df, str(crops_dir), transform=train_transform, mode='train')\n",
    "val_dataset = ImageDataset(val_df, str(crops_dir), transform=val_transform, mode='validation')\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3801ac71",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:27.038359Z",
     "iopub.status.busy": "2025-12-14T14:59:27.038164Z",
     "iopub.status.idle": "2025-12-14T14:59:27.788176Z",
     "shell.execute_reply": "2025-12-14T14:59:27.787468Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.754825,
     "end_time": "2025-12-14T14:59:27.789423",
     "exception": false,
     "start_time": "2025-12-14T14:59:27.034598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 189MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (backbone): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = SimpleCNN(num_classes=11, pretrained=True, freeze_backbone=True)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b4129f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:27.798117Z",
     "iopub.status.busy": "2025-12-14T14:59:27.797651Z",
     "iopub.status.idle": "2025-12-14T14:59:27.802794Z",
     "shell.execute_reply": "2025-12-14T14:59:27.802319Z"
    },
    "papermill": {
     "duration": 0.010473,
     "end_time": "2025-12-14T14:59:27.803800",
     "exception": false,
     "start_time": "2025-12-14T14:59:27.793327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 7. Training Setup\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "\n",
    "epochs = 10\n",
    "best_f1 = 0.0\n",
    "# Create experiment specific output directory\n",
    "exp_output_dir = dirs['output'] / exp_name\n",
    "exp_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Update model path to be inside experiment directory\n",
    "model_dir = exp_output_dir / 'models'\n",
    "model_dir.mkdir(exist_ok=True)\n",
    "best_model_path = model_dir / f\"{exp_name}_best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd3d5841",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:59:27.812086Z",
     "iopub.status.busy": "2025-12-14T14:59:27.811506Z",
     "iopub.status.idle": "2025-12-14T15:09:10.367290Z",
     "shell.execute_reply": "2025-12-14T15:09:10.366322Z"
    },
    "papermill": {
     "duration": 582.561408,
     "end_time": "2025-12-14T15:09:10.368700",
     "exception": false,
     "start_time": "2025-12-14T14:59:27.807292",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 [Train]: 100%|██████████| 201/201 [00:26<00:00,  7.66it/s, loss=1.69]\n",
      "Epoch 1/10 [Val]: 100%|██████████| 579/579 [00:57<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss: 1.7869, Val Loss: 2.3328, Val Macro F1: 0.3510\n",
      "New best model saved! F1: 0.3510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 [Train]: 100%|██████████| 201/201 [00:18<00:00, 10.94it/s, loss=1.31]\n",
      "Epoch 2/10 [Val]: 100%|██████████| 579/579 [00:38<00:00, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss: 1.3044, Val Loss: 2.2705, Val Macro F1: 0.3931\n",
      "New best model saved! F1: 0.3931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 [Train]: 100%|██████████| 201/201 [00:21<00:00,  9.49it/s, loss=0.967]\n",
      "Epoch 3/10 [Val]: 100%|██████████| 579/579 [00:36<00:00, 15.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss: 1.1555, Val Loss: 2.2726, Val Macro F1: 0.3998\n",
      "New best model saved! F1: 0.3998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 [Train]: 100%|██████████| 201/201 [00:19<00:00, 10.26it/s, loss=1.11]\n",
      "Epoch 4/10 [Val]: 100%|██████████| 579/579 [00:36<00:00, 15.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss: 1.0718, Val Loss: 2.2105, Val Macro F1: 0.4458\n",
      "New best model saved! F1: 0.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 [Train]: 100%|██████████| 201/201 [00:18<00:00, 10.58it/s, loss=1.19]\n",
      "Epoch 5/10 [Val]: 100%|██████████| 579/579 [00:35<00:00, 16.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss: 1.0159, Val Loss: 2.1978, Val Macro F1: 0.4539\n",
      "New best model saved! F1: 0.4539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 [Train]: 100%|██████████| 201/201 [00:17<00:00, 11.23it/s, loss=1.53]\n",
      "Epoch 6/10 [Val]: 100%|██████████| 579/579 [00:34<00:00, 16.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss: 0.9821, Val Loss: 2.2349, Val Macro F1: 0.4567\n",
      "New best model saved! F1: 0.4567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 [Train]: 100%|██████████| 201/201 [00:17<00:00, 11.47it/s, loss=1.3]\n",
      "Epoch 7/10 [Val]: 100%|██████████| 579/579 [00:37<00:00, 15.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss: 0.9529, Val Loss: 2.2459, Val Macro F1: 0.4648\n",
      "New best model saved! F1: 0.4648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 [Train]: 100%|██████████| 201/201 [00:18<00:00, 10.95it/s, loss=0.685]\n",
      "Epoch 8/10 [Val]: 100%|██████████| 579/579 [00:36<00:00, 15.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss: 0.9221, Val Loss: 2.2095, Val Macro F1: 0.4772\n",
      "New best model saved! F1: 0.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 [Train]: 100%|██████████| 201/201 [00:17<00:00, 11.30it/s, loss=1.19]\n",
      "Epoch 9/10 [Val]: 100%|██████████| 579/579 [00:37<00:00, 15.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss: 0.9190, Val Loss: 2.2323, Val Macro F1: 0.4742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 [Train]: 100%|██████████| 201/201 [00:18<00:00, 10.96it/s, loss=1.36]\n",
      "Epoch 10/10 [Val]: 100%|██████████| 579/579 [00:36<00:00, 16.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss: 0.8974, Val Loss: 2.2976, Val Macro F1: 0.4727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 8. Training Loop\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    train_pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} [Train]\")\n",
    "    for images, labels in train_pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * images.size(0)\n",
    "        train_pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    train_loss /= len(train_dataset)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} [Val]\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    val_loss /= len(val_dataset)\n",
    "    macro_f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Macro F1: {macro_f1:.4f}\")\n",
    "    \n",
    "    scheduler.step(macro_f1)\n",
    "    \n",
    "    if macro_f1 > best_f1:\n",
    "        best_f1 = macro_f1\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"New best model saved! F1: {best_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64345b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:09:10.953241Z",
     "iopub.status.busy": "2025-12-14T15:09:10.952892Z",
     "iopub.status.idle": "2025-12-14T15:09:44.999293Z",
     "shell.execute_reply": "2025-12-14T15:09:44.998351Z"
    },
    "papermill": {
     "duration": 34.285491,
     "end_time": "2025-12-14T15:09:45.000585",
     "exception": false,
     "start_time": "2025-12-14T15:09:10.715094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting prediction on Test Data (Q4)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 289/289 [00:33<00:00,  8.51it/s]\n"
     ]
    }
   ],
   "source": [
    "# 9. Test Prediction\n",
    "print(\"Starting prediction on Test Data (Q4)...\")\n",
    "if best_model_path.exists():\n",
    "    model.load_state_dict(torch.load(best_model_path))\n",
    "else:\n",
    "    print(\"Warning: No best model found, using last epoch model\")\n",
    "    \n",
    "model.eval()\n",
    "\n",
    "# Test dataset\n",
    "# For test, image_dir should be 'data/raw' as rel_paths are relative to it\n",
    "test_dataset = ImageDataset(test_meta, str(dirs['raw']), transform=val_transform, mode='test')\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for images in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "        test_preds.extend(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cbc41a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:09:45.488418Z",
     "iopub.status.busy": "2025-12-14T15:09:45.487611Z",
     "iopub.status.idle": "2025-12-14T15:09:45.527826Z",
     "shell.execute_reply": "2025-12-14T15:09:45.526955Z"
    },
    "papermill": {
     "duration": 0.285883,
     "end_time": "2025-12-14T15:09:45.529042",
     "exception": false,
     "start_time": "2025-12-14T15:09:45.243159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to /kaggle/working/kauto/competitions/submissions/submission_exp003_image_gpu.csv\n",
      "Submission shape: (9223, 1)\n",
      "Label distribution:\n",
      "label_id\n",
      "0       72\n",
      "1     1235\n",
      "2     1180\n",
      "3      845\n",
      "4     1238\n",
      "6     1083\n",
      "7      892\n",
      "8      692\n",
      "9     1386\n",
      "10     600\n",
      "Name: count, dtype: int64\n",
      "Results saved to /kaggle/working/kauto/competitions/output/exp003_image_gpu/exp003_image_gpu_results.json\n"
     ]
    }
   ],
   "source": [
    "# 10. Create Submission\n",
    "sub_path = dirs['submissions'] / f\"submission_{exp_name}.csv\"\n",
    "create_submission(test_preds, str(sub_path), test_meta)\n",
    "\n",
    "# Save results\n",
    "save_results({\n",
    "    'best_val_f1': best_f1,\n",
    "    'epochs': epochs,\n",
    "    'config': {\n",
    "        'backbone': 'resnet18',\n",
    "        'img_size': 224,\n",
    "        'batch_size': batch_size,\n",
    "        'train_size': len(train_dataset),\n",
    "        'val_size': len(val_dataset) \n",
    "    }\n",
    "}, str(exp_output_dir), exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41055390",
   "metadata": {
    "papermill": {
     "duration": 0.248442,
     "end_time": "2025-12-14T15:09:46.020303",
     "exception": false,
     "start_time": "2025-12-14T15:09:45.771861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9021091,
     "sourceId": 14153731,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 638.225871,
   "end_time": "2025-12-14T15:09:49.292362",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-14T14:59:11.066491",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
