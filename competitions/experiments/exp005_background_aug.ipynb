{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1a82f1e",
   "metadata": {
    "_cell_guid": "e90926bd-6615-4631-be1d-4994853d35da",
    "_uuid": "cfc0f635-07be-4a1a-876e-2aab9b8f5026",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.002304,
     "end_time": "2025-12-15T06:45:43.076361",
     "exception": false,
     "start_time": "2025-12-15T06:45:43.074057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exp005: Background Class & Augmentation\n",
    "\n",
    "## Objective\n",
    "Improve robustness against \"Garbage BBox\" in test data and generalization.\n",
    "\n",
    "## Strategy\n",
    "1.  **Background Class (Label -1)**:\n",
    "    - Include generated background crops (negative samples) in training.\n",
    "    - Classify into 12 classes (0-10: Players, 11: Background).\n",
    "    - Inference: Class 11 -> Output -1.\n",
    "2.  **Data Augmentation**:\n",
    "    - `RandomResizedCrop`: Improve robustness to bbox scale variations.\n",
    "    - `GaussianBlur`: Robustness to motion blur.\n",
    "    - `ColorJitter`: Slightly stronger than baseline.\n",
    "3.  **Validation**:\n",
    "    - StratifiedGroupKFold (Hold-out 20%) same as Exp004.\n",
    "    - Validate F1 score including class -1 (if we have -1 in val, which we will now!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d255faba",
   "metadata": {
    "_cell_guid": "8474dbdc-ad8f-458c-b4a8-efa5cb407864",
    "_uuid": "557d20a3-1f99-40f3-ba81-8a5c045b7b8a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-15T06:45:43.081154Z",
     "iopub.status.busy": "2025-12-15T06:45:43.080577Z",
     "iopub.status.idle": "2025-12-15T06:45:55.420012Z",
     "shell.execute_reply": "2025-12-15T06:45:55.419173Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 12.343312,
     "end_time": "2025-12-15T06:45:55.421435",
     "exception": false,
     "start_time": "2025-12-15T06:45:43.078123",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into '/kaggle/working/kauto'...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedGroupKFold\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "# Detect environment\n",
    "IS_KAGGLE = os.path.exists(\"/kaggle/input\")\n",
    "ROOT_DIR = Path(\"/kaggle/working/kauto/competitions\") if IS_KAGGLE else Path(__file__).resolve().parents[1]\n",
    "DATA_DIR = Path(\"/kaggle/input/atmacup22\") if IS_KAGGLE else Path(__file__).resolve().parents[1]\n",
    "\n",
    "# Clone repository if on Kaggle\n",
    "if IS_KAGGLE:\n",
    "    if not (Path(\"/kaggle/working/kauto\").exists()):\n",
    "        os.system(\"git clone https://github.com/tatsukisato/kauto.git /kaggle/working/kauto\")\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "else:\n",
    "    sys.path.append(str(ROOT_DIR))\n",
    "\n",
    "try:\n",
    "    from src.utils import setup_directories, save_results, create_submission, print_experiment_info, crop_and_save_images\n",
    "    from src.cnn_model import SimpleCNN\n",
    "    from src.dataset import AtmaCup22Dataset\n",
    "    # Import generating function specially\n",
    "    from src.generate_background import generate_background_samples\n",
    "except ImportError:\n",
    "    print(\"Warning: Custom modules not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a3e4c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-15T06:45:55.425862Z",
     "iopub.status.busy": "2025-12-15T06:45:55.425503Z",
     "iopub.status.idle": "2025-12-15T06:45:55.432050Z",
     "shell.execute_reply": "2025-12-15T06:45:55.431472Z"
    },
    "papermill": {
     "duration": 0.009993,
     "end_time": "2025-12-15T06:45:55.433150",
     "exception": false,
     "start_time": "2025-12-15T06:45:55.423157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Custom Dataset to handle both original crops (by index) and BG crops (by filename)\n",
    "class MixedImageDataset(Dataset):\n",
    "    def __init__(self, meta_df, crop_dirs, transform=None, mode='train'):\n",
    "        \"\"\"\n",
    "        crop_dirs: dict {'train': path_to_player_crops, 'bg': path_to_bg_crops}\n",
    "        \"\"\"\n",
    "        self.meta_df = meta_df.reset_index(drop=True)\n",
    "        self.crop_dirs = crop_dirs\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta_df.iloc[idx]\n",
    "        label = int(row['label_id'])\n",
    "        \n",
    "        # Determine image path\n",
    "        if label == -1:\n",
    "            # Background image: filename should be in 'file_name' column\n",
    "            fname = row.get('file_name', f\"bg_{row.name}.jpg\") # Fallback\n",
    "            img_path = self.crop_dirs['bg'] / fname\n",
    "        else:\n",
    "            # Player image: saved as {original_index}.jpg\n",
    "            idx_name = row.get('original_index', row.name)\n",
    "            img_path = self.crop_dirs['train'] / f\"{idx_name}.jpg\"\n",
    "\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            # Fallback black image\n",
    "            img = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "            \n",
    "        if self.mode in ['train', 'validation']:\n",
    "            # Map -1 to 11 for CrossEntropy\n",
    "            target = 11 if label == -1 else label\n",
    "            return img, torch.tensor(target, dtype=torch.long)\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f8cf5c0",
   "metadata": {
    "_cell_guid": "532cf704-4a69-40f6-b20d-4f7ab4801a85",
    "_uuid": "386a1f4d-92a4-409c-8549-3250e2ec30e2",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-12-15T06:45:55.437338Z",
     "iopub.status.busy": "2025-12-15T06:45:55.437125Z",
     "iopub.status.idle": "2025-12-15T07:07:01.193396Z",
     "shell.execute_reply": "2025-12-15T07:07:01.192382Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 1265.883898,
     "end_time": "2025-12-15T07:07:01.318627",
     "exception": false,
     "start_time": "2025-12-15T06:45:55.434729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Train data shape: (24920, 9)\n",
      "Test data shape: (9223, 9)\n",
      "Generating Background Samples...\n",
      "Found 2495 unique images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Background: 100%|██████████| 2495/2495 [02:13<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 2495 background samples.\n",
      "Original Train: 24920\n",
      "Background: 2495\n",
      "Total Train: 27415\n",
      "\n",
      "==================== Hold-out Validation (20%) ====================\n",
      "Train: 21871, Val: 5544\n",
      "Using device: cuda, AMP: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 198MB/s]\n",
      "Ep 1/12: 100%|██████████| 86/86 [01:34<00:00,  1.10s/it, loss=1.67]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.8650, Val F1: 0.3392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 2/12: 100%|██████████| 86/86 [01:23<00:00,  1.03it/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.6825, Val F1: 0.4354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 3/12: 100%|██████████| 86/86 [01:23<00:00,  1.03it/s, loss=1.38]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.5951, Val F1: 0.4642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 4/12: 100%|██████████| 86/86 [01:22<00:00,  1.04it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.5656, Val F1: 0.4683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 5/12: 100%|██████████| 86/86 [01:21<00:00,  1.05it/s, loss=1.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.5524, Val F1: 0.4801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 6/12: 100%|██████████| 86/86 [01:22<00:00,  1.04it/s, loss=1.21]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.5117, Val F1: 0.4885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 7/12: 100%|██████████| 86/86 [01:22<00:00,  1.04it/s, loss=1.01]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.4883, Val F1: 0.5056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 8/12: 100%|██████████| 86/86 [01:21<00:00,  1.05it/s, loss=1.29]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.4848, Val F1: 0.4987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 9/12: 100%|██████████| 86/86 [01:22<00:00,  1.05it/s, loss=1.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.4291, Val F1: 0.5206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 10/12: 100%|██████████| 86/86 [01:23<00:00,  1.03it/s, loss=1.11]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.4891, Val F1: 0.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 11/12: 100%|██████████| 86/86 [01:23<00:00,  1.03it/s, loss=0.999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.4330, Val F1: 0.5242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ep 12/12: 100%|██████████| 86/86 [01:22<00:00,  1.04it/s, loss=1.17]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val Loss: 1.3905, Val F1: 0.5390\n",
      "Best Val F1: 0.5390\n",
      "Submission saved to /kaggle/working/submissions/submission_exp005_background_aug.csv\n",
      "Submission shape: (9223, 1)\n",
      "Label distribution:\n",
      "label_id\n",
      "-1     1063\n",
      " 0      248\n",
      " 1      714\n",
      " 2      610\n",
      " 3      710\n",
      " 4      809\n",
      " 5      885\n",
      " 6     1136\n",
      " 7      673\n",
      " 8      659\n",
      " 9     1213\n",
      " 10     503\n",
      "Name: count, dtype: int64\n",
      "Results saved to /kaggle/working/output/exp005_background_aug/exp005_background_aug_results.json\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    exp_name = \"exp005_background_aug\"\n",
    "    description = \"Add Background Class (-1) and Stronger Augmentations (RandomResizedCrop, Blur). Mixed Dataset.\"\n",
    "    \n",
    "    DEBUG = not IS_KAGGLE\n",
    "    EPOCHS = 2 if DEBUG else 12 \n",
    "    \n",
    "    # Setup Directories\n",
    "    dirs = setup_directories(\n",
    "        base_dir=str(Path(\"/kaggle/working\") if IS_KAGGLE else ROOT_DIR), \n",
    "        data_dir=str(DATA_DIR)\n",
    "    )\n",
    "    print_experiment_info(exp_name, description)\n",
    "    \n",
    "    # 1. Load Data\n",
    "    raw_dir = dirs['raw']\n",
    "    dataset_handler = AtmaCup22Dataset(data_dir=str(raw_dir))\n",
    "    train_meta, test_meta = dataset_handler.load_data()\n",
    "    \n",
    "    # Keep original index for filename mapping\n",
    "    train_meta['original_index'] = train_meta.index\n",
    "    \n",
    "    # Define Groups\n",
    "    groups = train_meta['quarter']\n",
    "\n",
    "    if DEBUG:\n",
    "        print(\"!!! DEBUG MODE: Using small subset !!!\")\n",
    "        # Ensure we have multiple groups (quarters) for StratifiedGroupKFold\n",
    "        # Simply taking head(200) might result in only 1 group (e.g. Q1-000)\n",
    "        unique_quarters = train_meta['quarter'].unique()\n",
    "        if len(unique_quarters) >= 2:\n",
    "            # Take first 100 rows from first 2 quarters\n",
    "            q1_df = train_meta[train_meta['quarter'] == unique_quarters[0]].head(100)\n",
    "            q2_df = train_meta[train_meta['quarter'] == unique_quarters[1]].head(100)\n",
    "            train_meta = pd.concat([q1_df, q2_df])\n",
    "        else:\n",
    "            # Fallback if only 1 quarter exists (unlikely for full data)\n",
    "            train_meta = train_meta.iloc[:200]\n",
    "            \n",
    "        test_meta = test_meta.iloc[:50]\n",
    "        # Update groups based on new train_meta\n",
    "        groups = train_meta['quarter']\n",
    "        # Note: N_FOLDS isn't used directly here as we hardcoded 5 later, \n",
    "        # but the concept holds.\n",
    "        \n",
    "    # 2. Check/Generate Player Crops\n",
    "    crops_dir = dirs['processed'] / 'crops_train'\n",
    "    current_crops = list(crops_dir.glob(\"*.jpg\")) if crops_dir.exists() else []\n",
    "    if len(current_crops) < len(train_meta) * 0.9: \n",
    "        print(f\"Generating player crops...\")\n",
    "        crop_and_save_images(train_meta, dirs['raw'], crops_dir, mode='train')\n",
    "    \n",
    "    # 3. Check/Generate Background Crops\n",
    "    bg_crops_dir = Path('.') / 'crops_bg'\n",
    "    # bg_crops_dir = dirs['processed'] / 'crops_bg'\n",
    "    bg_csv_path = dirs['processed'] / 'train_meta_background.csv'\n",
    "    \n",
    "    # Generate BG if needed\n",
    "    if not bg_csv_path.exists() or len(list(bg_crops_dir.glob(\"*.jpg\"))) < 10:\n",
    "        print(\"Generating Background Samples...\")\n",
    "        bg_df = generate_background_samples(\n",
    "            train_meta=train_meta,\n",
    "            raw_dir=dirs['raw'],\n",
    "            output_dir=bg_crops_dir,\n",
    "            samples_per_image=1, # 1 per image\n",
    "            bg_label=-1\n",
    "        )\n",
    "    else:\n",
    "        print(\"Loading existing Background Samples...\")\n",
    "        bg_df = pd.read_csv(bg_csv_path)\n",
    "        \n",
    "    # Merge Data\n",
    "    bg_df['original_index'] = -1 # indicator for BG\n",
    "    full_train_df = pd.concat([train_meta, bg_df], axis=0, ignore_index=True)\n",
    "    \n",
    "    print(f\"Original Train: {len(train_meta)}\")\n",
    "    print(f\"Background: {len(bg_df)}\")\n",
    "    print(f\"Total Train: {len(full_train_df)}\")\n",
    "\n",
    "    # 4. Transforms (Stronger)\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.6, 1.0), ratio=(0.8, 1.2)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.1),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 5. Validation Split\n",
    "    sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    exp_output_dir = dirs['output'] / exp_name\n",
    "    exp_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    model_dir = exp_output_dir / 'models'\n",
    "    model_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    groups = full_train_df['quarter']\n",
    "    X = full_train_df.index\n",
    "    y = full_train_df['label_id'].astype(str)\n",
    "    \n",
    "    train_idx, val_idx = next(sgkf.split(X, y, groups=groups))\n",
    "    \n",
    "    print(f\"\\n{'='*20} Hold-out Validation (20%) {'='*20}\")\n",
    "    train_df_fold = full_train_df.iloc[train_idx]\n",
    "    val_df_fold = full_train_df.iloc[val_idx]\n",
    "    print(f\"Train: {len(train_df_fold)}, Val: {len(val_df_fold)}\")\n",
    "    \n",
    "    # Datasets\n",
    "    crop_dirs = {'train': crops_dir, 'bg': bg_crops_dir}\n",
    "    train_dataset = MixedImageDataset(train_df_fold, crop_dirs, transform=train_transform, mode='train')\n",
    "    val_dataset = MixedImageDataset(val_df_fold, crop_dirs, transform=val_transform, mode='validation')\n",
    "    \n",
    "    batch_size = 32 if DEBUG else 256\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 6. Model (12 Classes)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    use_amp = device.type == \"cuda\"\n",
    "    print(f\"Using device: {device}, AMP: {use_amp}\")\n",
    "    \n",
    "    model = SimpleCNN(num_classes=12, pretrained=True, freeze_backbone=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2)\n",
    "    scaler = GradScaler(enabled=use_amp)\n",
    "    \n",
    "    best_score = 0.0\n",
    "    best_model_path = model_dir / f\"{exp_name}_best.pth\"\n",
    "    \n",
    "    # Training Loop\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        pbar = tqdm(train_loader, desc=f\"Ep {epoch+1}/{EPOCHS}\")\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "            pbar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        train_loss /= len(train_dataset)\n",
    "        \n",
    "        # Val\n",
    "        model.eval()\n",
    "        val_preds = []\n",
    "        val_labels = []\n",
    "        val_loss = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "                    outputs = model(images)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                \n",
    "                preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "                val_preds.extend(preds)\n",
    "                val_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_loss /= len(val_dataset)\n",
    "        macro_f1 = f1_score(val_labels, val_preds, average='macro')\n",
    "        print(f\"  Val Loss: {val_loss:.4f}, Val F1: {macro_f1:.4f}\")\n",
    "        \n",
    "        if macro_f1 > best_score:\n",
    "            best_score = macro_f1\n",
    "            torch.save(model.state_dict(), best_model_path)\n",
    "            \n",
    "        scheduler.step(macro_f1)\n",
    "        \n",
    "    print(f\"Best Val F1: {best_score:.4f}\")\n",
    "    \n",
    "    # Inference on Test\n",
    "    model.load_state_dict(torch.load(best_model_path, map_location=device))\n",
    "    model.eval()\n",
    "    \n",
    "    from src.image_dataset import ImageDataset as StandardImageDataset\n",
    "    test_dataset = StandardImageDataset(test_meta, str(dirs['raw']), transform=val_transform, mode='test')\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    \n",
    "    final_test_preds = []\n",
    "    with torch.no_grad():\n",
    "        for images in test_loader:\n",
    "            images = images.to(device)\n",
    "            with autocast(device_type=\"cuda\", enabled=use_amp):\n",
    "                outputs = model(images)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            # Map 11 -> -1\n",
    "            preds = np.where(preds == 11, -1, preds)\n",
    "            final_test_preds.extend(preds)\n",
    "            \n",
    "    # Submission\n",
    "    sub_path = dirs['submissions'] / f\"submission_{exp_name}.csv\"\n",
    "    create_submission(final_test_preds, str(sub_path), test_meta)\n",
    "    \n",
    "    save_results({\n",
    "        'val_score': best_score,\n",
    "        'config': {\n",
    "            'aug': 'RandomResizedCrop+Blur',\n",
    "            'classes': 'Includes Background(-1)',\n",
    "            'epochs': EPOCHS\n",
    "        }\n",
    "    }, str(exp_output_dir), exp_name)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cceaba",
   "metadata": {
    "papermill": {
     "duration": 0.122488,
     "end_time": "2025-12-15T07:07:01.565942",
     "exception": false,
     "start_time": "2025-12-15T07:07:01.443454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 9021091,
     "sourceId": 14153731,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1285.096705,
   "end_time": "2025-12-15T07:07:04.783148",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-15T06:45:39.686443",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
