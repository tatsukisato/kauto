# 学んだこと・Tips

このドキュメントには、コンペを通じて学んだことや今後に活かせるTipsを記録します。

## ⚠️ 重要な仕様変更（2025-12-14更新）

### テストデータの形式変更

**発見**: テストデータは完全画像ではなく、**bbox領域を切り抜いた画像（crop画像）**

**影響**:
1. 学習時に完全画像を使用すると、テストデータとのギャップが大きい
2. コンテキスト情報（周囲の選手、コート全体）が失われる
3. bbox位置情報（x, y, w, h）の意味が変わる

**対応策**:
- 学習時もbbox領域のみを切り抜いて使用する
- データ拡張時にbboxのサイズや位置を変動させる
- 切り抜き画像に特化した特徴量を使用する

### bbox精度の問題

**発見**: テストデータのbboxは**常に正しいとは限らない**

**問題**:
- bboxの数が多すぎる（誤検出）
- bboxの数が少なすぎる（検出漏れ）
- 選手でないものがbboxとして検出される

**対応策**:
- `-1` (unknown) の予測戦略が重要
- 信頼度スコアを活用して、低信頼度のbboxを `-1` と予測
- bboxの品質を評価する補助モデルの検討

### 画角の混在

**発見**: テストデータでは**上・横どちらか一方のみ**の場合がある

**対応策**:
- 片方の画角のみでも識別できるモデルが必要
- 両方の画角で別々にモデルを学習
- マルチモーダル学習（両方の画角を使える場合は活用）

### bboxの重なり

**発見**: 同一選手の重複bboxが存在する

**対応策**:
- 重なっているbboxを検出するロジックが必要
- 同一選手と判定した場合、両方に同じIDを出力
- Non-Maximum Suppression (NMS) の活用を検討

## 技術的な学び

### データ処理

#### ラベルの非連続性への対処
**問題**: LightGBMは連続したラベル（0, 1, 2, ...）を期待するが、実際のラベルは非連続（0, 1, 2, 3, 4, 6, 7, 8, 9, 10）

**解決策**: ラベルマッピングを実装
```python
# 学習時: 元のラベル → 連続インデックス
unique_labels = np.unique(y_train)
label_mapping = {label: idx for idx, label in enumerate(sorted(unique_labels))}
y_train_mapped = np.array([label_mapping[label] for label in y_train])

# 予測時: 連続インデックス → 元のラベル
inverse_mapping = {idx: label for label, idx in label_mapping.items()}
predictions = np.array([inverse_mapping[idx] for idx in predictions_idx])
```

#### JSON保存時の型エラー
**問題**: `numpy.int64`型のキーがJSON保存できない

**解決策**: 標準Python型に変換
```python
results['per_class_f1'][int(label)] = float(f1)
```

### バリデーション戦略

#### 時系列データの分割
**学び**: テストデータがQ4のみだが、学習データにはQ1とQ2のみ
- 当初Q4をバリデーションに使う予定だったが、データに存在しない
- Q1を学習、Q2をバリデーションに変更

**教訓**: データの構成を事前に十分確認する

### 環境構築

#### 仮想環境の活用
**問題**: `uv run`で実行時にライブラリが見つからない

**解決策**: 
```bash
source ../.venv/bin/activate
python experiments/exp001_baseline.py
```

## ドメイン知識

### バスケットボール選手の識別

#### 位置情報のみの限界
- bbox位置だけではMacro F1が0.17程度
- Player 4が最も識別しやすい（F1=0.31）→ 特定の位置に多く出現する可能性

#### 画角の重要性
- **side (横から)**: 背番号や横顔が見える
- **top (上から)**: 位置関係や動きが見える
- 両方を組み合わせることで精度向上が期待できる

### クラス不均衡への対応

#### 選手の入れ替え
- Player 0はQ1のみ、Player 5はQ2のみに登場
- テストデータ(Q4)に未知の選手が登場する可能性
- `-1` (unknown)の予測が必要になる場合がある

## プロジェクト管理

### ディレクトリ構成

#### 共通ソースコードの分離
**良かった点**:
- `src/`を共通化することで複数コンペで再利用可能
- 実験スクリプトとロジックを分離

**改善点**:
- 設定ファイル（YAML）の活用度を上げる
- ドキュメントを充実させる

### 実験管理

#### 命名規則
- `exp001_baseline.py`: 実験スクリプト
- `output/exp001_baseline/`: 実験結果
- `submissions/exp001_baseline.csv`: サブミッション

**メリット**: 実験の追跡が容易

## Exp002での重要な発見 (2025-12-14追記)

### 1. 致命的なクラス分布の不一致
**発見**:
- 学習データ(Q1)と検証データ(Q2)で出現する選手が完全に異なる場合がある
- 例: Player 0はQ1のみ、Player 5はQ2のみに出現

**影響**:
- Q1で学習したモデルはPlayer 5を知らないため、Q2の検証で必ず間違える
- Q2に学習データが存在しないため、Q2でのPlayer 5への推論能力は未知数
- ValidationスコアとLBスコアの相関が取れなくなる

**対応策**:
- **Stratified K-Fold**: クオーターで分割せず、全データを混ぜてから選手IDの比率を保ったまま分割する
- これによりTrain/Val共に全選手が含まれ、正当な評価が可能になる

### 2. 「ゴミbbox (False Positive)」への耐性不足
**発見**:
- 学習データは「完全な正解bbox」のみで構成されている
- テストデータは機械検出のため、「選手でない背景」などのゴミbboxが含まれる
- 現行モデルはゴミ入力に対しても無理やり0-10のIDを予測してしまう

**対応策案**:
1.  **Backgroundクラスの導入 (推奨)**:
    - 学習データに「背景のみ」の画像をLabel -1として追加する
    - ランダムクロップや、選手bbox以外の領域を切り抜いて作成
2.  **信頼度閾値 (Confidence Thresholding)**:
    - 予測確率(Softmax)の最大値が低い場合(例: < 0.5)はUnknownとする
3.  **エントロピー閾値**:
    - 予測分布のエントロピーが高い(迷っている)場合はUnknownとする
4.  **異常検知 (OOD Detection)**:
    - 選手クラスの分布から外れているものを検出する専用ロジック
5.  **二値分類モデルの併用**:
    - 「選手か否か」を判定するモデルを前段に挟む

**次の一手**:
- Exp003以降では、まずValidation戦略を修正し、次にBackgroundクラスの導入を試みる

## 次回に向けて

### すぐに試すべきこと
1. **画像特徴の追加**: CNNで抽出した特徴をLightGBMに追加
2. **時系列特徴**: 前後フレームとの差分（動きの情報）
3. **アンサンブル**: 複数モデルの組み合わせ

### 長期的な改善
1. **ディープラーニング**: YOLO等の物体検出モデル
2. **データ拡張**: 画像の回転、反転等
3. **外部データ**: 選手の身長、ポジション等

## 参考リンク

- [LightGBM Documentation](https://lightgbm.readthedocs.io/)
- [Scikit-learn Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html)

---

**最終更新**: 2025-12-13
