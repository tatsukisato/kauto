# 学んだこと・Tips (Lessons Learned)

コンペティションを通じて得られた知見、技術的なTips、実験から得られた重要な発見を記録します。

## 🧪 実験からの主要な発見と進化

### Exp005: Background Classによる頑健性の向上 (2025-12-15)

**【結果】**
*   **CV**: 0.6604 (Exp004) -> 0.5390 (Exp005)
*   **Public LB**: 0.5434 (Exp004) -> 0.5043 (Exp005)
*   **CV - LB Gap**: **0.117 -> 0.035** (大幅に改善！)

**【重要な学び】**
1.  **「相関するバリデーションの確立」**:
    *   Exp004ではCVが0.66と高かったが、LBは0.54と乖離があった。これは「ゴミbbox（背景）」を学習していないモデルが、テストデータ中のゴミを無理やり選手に分類していたため。
    *   Exp005で「Backgroundクラス（Label -1）」を導入し、**ゴミをゴミとして正しく検出するタスク**に変えたことで、スコア自体は下がったものの、CVとLBの乖離が埋まり、信頼できるベースラインが完成した。
2.  **「タスクの難化と本質的な改善」**:
    *   11クラス分類から12クラス分類（+背景）になり、さらにBBoxの位置ズレも許容する必要があるデータ拡張を入れたため、タスク自体は難しくなった。
    *   しかし、これが実運用（テストデータ）に近い環境であり、今後はこの環境でスコアを上げていくことが本質的な改善につながる。

---

### Exp004: Validation戦略の確立 (2025-12-15)

**【結果】**
GPU環境での学習パイプラインが確立し、適切なValidationスコアが得られるようになりました。

**【重要な学び: なぜ精度が向上したのか？】**
Exp002からモデル構造（ResNet18）は変更していませんが、Validation戦略の変更が決定的な差を生みました。

1.  **「全クラスの網羅 (Class Coverage)」**:
    *   Exp002 (Train=Q1, Val=Q2) では、Q1にしかいない選手(Player 0)を学習し、見たことのないQ2の選手(Player 5など)をテストするという「無理ゲー」状態でした。
    *   Exp004では全データをシャッフルして分割したため、モデルは**全11クラス（選手）の特徴を学習**できました。単なるデータ量の増加ではなく、「学習できていなかったクラスが学習できるようになった」ことが最大の要因です。
2.  **「Temporal Leakageの防止」**:
    *   単純なシャッフルではなく `StratifiedGroupKFold(group=quarter)` を採用したことで、同一シーン（連続フレーム）がTrain/Valに混入するリークを防ぎつつ、正しい評価ができるようになりました。
3.  **「実験サイクルの高速化」**:
    *   5-Foldすべてを行うのではなく、Hold-out (20%) 検証に切り替えることで、信頼できる指標を維持したまま試行回数を増やせる体制を整えました。

---

## ⚠️ データセットの仕様に関する発見

| 項目 | 発見内容 | 対策・考慮事項 |
| :--- | :--- | :--- |
| **テストデータ形式** | 完全画像ではなく **bbox切り抜き(Crop)** 画像のみ提供される。 | 学習時もCrop画像を使用し、環境（背景）コンテキストに依存しすぎないモデルを作る必要がある。 |
| **bbox精度** | テストデータのbboxは機械検出のため、**ゴミ（非選手）**が含まれる。 | `label_id=-1` (Unknown) の予測が必要。Confidence thresholdingやBackgroundクラスの導入を検討。 |
| **クラス分布** | 選手によって登場するQuarterが偏っている（例: Player 0はQ1のみ）。 | **Stratified Splitが必須**。時系列分割（Q1学習→Q2検証）は機能しない。 |

## 🛠 技術的Tips

### 環境・ワークフロー
*   **Hybrid Workflow**: ロジック実装・デバッグはローカル(Small Data)、本番学習はKaggle GPU(Full Data)という分担が効率的。
*   **パスの抽象化**: `base_dir` (Output) と `data_dir` (Input) を引数で分離することで、環境差異をコード変更なしで吸収できる。

### データ処理
*   **ラベルマッピング**: 不連続なラベル(0,1,3,...)を扱う際は、一度連続値(0,1,2...)に変換して学習し、推論後に戻す処理が必要。
*   **JSONシリアライズ**: `numpy`型（int64など）はそのままJSON保存できないため、標準の `int()` `float()` にキャストする必要がある。

## 📝 過去の実験ログ（アーカイブ）

### Exp002: Image Baseline (失敗)
*   **戦略**: Q1で学習、Q2で検証。
*   **失敗原因**: クラス分布の不一致（未知の選手に対する推論）。Validationスコアが全く参考にならなかった。
*   **収穫**: バリデーション戦略の重要性を再認識。

### Exp001: Table Data Baseline (LightGBM)
*   **戦略**: bbox位置情報（x, y, w, h）のみを使用。
*   **結果**: F1スコアが低い（位置情報だけでは選手識別は困難）。
*   **収穫**: ベースラインの作成と提出フローの確立。

---
**最終更新**: 2025-12-15
